################################################################################
### AUTO-GPT - GENERAL SETTINGS
################################################################################
# EXECUTE_LOCAL_COMMANDS - Allow local command execution (Example: False)
EXECUTE_LOCAL_COMMANDS=False
# BROWSE_CHUNK_MAX_LENGTH - When browsing website, define the length of chunk stored in memory
BROWSE_CHUNK_MAX_LENGTH=8192
# BROWSE_SUMMARY_MAX_TOKEN - Define the maximum length of the summary generated by GPT agent when browsing website
BROWSE_SUMMARY_MAX_TOKEN=300
# USER_AGENT - Define the user-agent used by the requests library to browse website (string)
# USER_AGENT="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36"
# AI_SETTINGS_FILE - Specifies which AI Settings file to use (defaults to ai_settings.yaml)
AI_SETTINGS_FILE=clara_settings.yaml
# USE_WEB_BROWSER - Sets the web-browser drivers to use with selenium (defaults to chrome).
# Note: set this to either 'chrome', 'firefox', or 'safari' depending on your current browser
# USE_WEB_BROWSER=chrome
TEMPERATURE=0.36

################################################################################
### LLM MODELS
################################################################################

# SMART_LLM_MODEL - Smart language model (Default: gpt-4)
# FAST_LLM_MODEL - Fast language model (Default: gpt-3.5-turbo)
SMART_LLM_MODEL=/app/model-lib/llama-7b.ggmlv3.q2_K.bin
FAST_LLM_MODEL=/app/model-lib/pllama-7b.ggmlv3.q2_K.bin

### LLM MODEL SETTINGS
# FAST_TOKEN_LIMIT - Fast token limit for OpenAI (Default: 4000), depends on your model
# SMART_TOKEN_LIMIT - Smart token limit for OpenAI (Default: 8000), depends on your model
# EMBED_DIM - embed dimemsion, depends on your model (1536 was in Auto-GPT settings, 8192 for llama-q4, 4096 for GPT4ALL)
# When using --gpt3only this needs to be set to 4000.
FAST_TOKEN_LIMIT=1500
SMART_TOKEN_LIMIT=2000
EMBED_DIM=4096
#if you dont know the value, check this variable in your terminal llama_model_load_internal: n_embd

################################################################################
### MEMORY
################################################################################

### MEMORY_BACKEND - Memory backend type
# local - Default
# pinecone - Pinecone (if configured)
# redis - Redis (if configured)
MEMORY_BACKEND=redis

### REDIS
# REDIS_HOST - Redis host (Default: localhost)
# REDIS_PORT - Redis port (Default: 6379)
# REDIS_PASSWORD - Redis password (Default: "")
# WIPE_REDIS_ON_START - Wipes data / index on start (Default: False)
# MEMORY_INDEX - Name of index created in Redis database (Default: auto-gpt)
REDIS_HOST=redis-auto-llama
REDIS_PORT=6379
REDIS_PASSWORD=
WIPE_REDIS_ON_START=False
MEMORY_INDEX=auto-llama

### GOOGLE
# GOOGLE_API_KEY - Google API key (Example: my-google-api-key)
# CUSTOM_SEARCH_ENGINE_ID - Custom search engine ID (Example: my-custom-search-engine-id)
GOOGLE_API_KEY=AIzaSyA5fhBR8TkWoYUcx5XeVl3UP9Yj_n2paaA
CUSTOM_SEARCH_ENGINE_ID=1283ef5af66844ad2

### HUGGINGFACE
# STABLE DIFFUSION
# (Default URL: https://api-inference.huggingface.co/models/CompVis/stable-diffusion-v1-4)
# Set in image_gen.py)
# HUGGINGFACE_API_TOKEN - HuggingFace API token (Example: my-huggingface-api-token)
HUGGINGFACE_API_TOKEN=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

################################################################################
### TTS PROVIDER
################################################################################

### MAC OS
# USE_MAC_OS_TTS - Use Mac OS TTS or not (Default: False)
USE_MAC_OS_TTS=False
